{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question 1 part a and b\n",
      "confusion matrix for k=1\n",
      "[[ 93  25]\n",
      " [ 19 200]]\n",
      "accuracy for k=1 0.8694362017804155\n",
      "\n",
      "confusion matrix for k=3\n",
      "[[ 92  26]\n",
      " [  9 210]]\n",
      "accuracy for k=3 0.8961424332344213\n",
      "\n",
      "confusion matrix for k=5\n",
      "[[ 92  26]\n",
      " [ 10 209]]\n",
      "accuracy for k=5 0.8931750741839762\n",
      "\n",
      "max accuracy 0.8961424332344213\n",
      "\n",
      "K=3 has max accuracy\n",
      "question 2 part a and b\n",
      "confusion matrix for k=1\n",
      "[[115   3]\n",
      " [ 13 206]]\n",
      "accuracy for k=1 0.9525222551928784\n",
      "\n",
      "confusion matrix for k=3\n",
      "[[116   2]\n",
      " [ 14 205]]\n",
      "accuracy for k=3 0.9525222551928784\n",
      "\n",
      "confusion matrix for k=5\n",
      "[[116   2]\n",
      " [ 13 206]]\n",
      "accuracy for k=5 0.9554896142433235\n",
      "\n",
      "max accuracy 0.9554896142433235\n",
      "\n",
      "K=5 has max accuracy\n",
      "question 3\n",
      "\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'covariance_0.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-137-170fe89ac3b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[0mmatrix0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumn_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[0mcovari0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatrix0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcov\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecimals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m \u001b[0mcovari0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'covariance_0.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Mean of class 0:\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmean0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;31m# sample mean and covariance for class 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Pictures\\anaconda\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors)\u001b[0m\n\u001b[0;32m   3168\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3169\u001b[0m         )\n\u001b[1;32m-> 3170\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3172\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Pictures\\anaconda\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m             f, handles = get_handle(\n\u001b[0m\u001b[0;32m    186\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Pictures\\anaconda\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors)\u001b[0m\n\u001b[0;32m    491\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[1;31m# No explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'covariance_0.csv'"
     ]
    }
   ],
   "source": [
    "#question 1\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "data= pd.read_csv(\"SteelPlateFaults-2class.csv\")\n",
    "\n",
    "# storing column names\n",
    "column = data.columns.to_numpy()\n",
    "# splitting the dataset according to class\n",
    "grouping= data.groupby('Class')\n",
    "\n",
    "# converting the class data into numpy array\n",
    "class0 = grouping.get_group(0).to_numpy()\n",
    "class1 = grouping.get_group(1).to_numpy()\n",
    "\n",
    "# splitting the classes dataset into training and testing sets\n",
    "train0, test0 = train_test_split(class0, test_size=0.30, random_state=42, shuffle=True)\n",
    "train1, test1 = train_test_split(class1, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "# combining the class wise splitted dataset\n",
    "training = np.concatenate((train0, train1), axis=0)\n",
    "testing = np.concatenate((test0, test1), axis=0)\n",
    "\n",
    "# converting the splitted data into dataframe\n",
    "train = pd.DataFrame(training, columns=column)\n",
    "test = pd.DataFrame(testing, columns=column)\n",
    "\n",
    "# saving the data of train and test into csv file\n",
    "train.to_csv('SteelPlateFaults-train.csv')\n",
    "test.to_csv('SteelPlateFaults-test.csv')\n",
    "\n",
    "#applying KNN method to training and testing data\n",
    "train_data= pd.read_csv(\"SteelPlateFaults-train.csv\")\n",
    "test_data=pd.read_csv(\"SteelPlateFaults-test.csv\")\n",
    "train_y=train_data['Class']\n",
    "train_x=train_data.drop(['Class'], axis = 1)\n",
    "test_data= pd.read_csv(\"SteelPlateFaults-test.csv\")\n",
    "test_y=test_data['Class']\n",
    "test_x=test_data.drop(['Class'], axis = 1)\n",
    "\n",
    "#part a and b of question 1\n",
    "print(\"question 1 part a and b\")\n",
    "#for K=1\n",
    "classifier1= KNeighborsClassifier(n_neighbors=1, metric='minkowski', p=2 )  \n",
    "classifier1.fit(train_x, train_y)\n",
    "\n",
    "#Predicting the test set result  \n",
    "y1_pred= classifier1.predict(test_x)  \n",
    "cm1= confusion_matrix(test_y, y1_pred)\n",
    "as1= accuracy_score(test_y, y1_pred)\n",
    "print(\"confusion matrix for k=1\")\n",
    "print(cm1)\n",
    "print(\"accuracy for k=1\",as1)\n",
    "\n",
    "#for K=3\n",
    "classifier3= KNeighborsClassifier(n_neighbors=3, metric='minkowski', p=2 )  \n",
    "classifier3.fit(train_x, train_y)\n",
    "\n",
    "#Predicting the test set result  \n",
    "y3_pred= classifier3.predict(test_x)  \n",
    "cm3= confusion_matrix(test_y, y3_pred)\n",
    "as3= accuracy_score(test_y, y3_pred)\n",
    "print()\n",
    "print(\"confusion matrix for k=3\")\n",
    "print(cm3)\n",
    "print(\"accuracy for k=3\",as3)\n",
    "\n",
    "#for K=5\n",
    "classifier5= KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2 ) \n",
    "classifier5.fit(train_x, train_y)\n",
    "\n",
    "#Predicting the test set result  \n",
    "y5_pred= classifier5.predict(test_x)  \n",
    "cm5= confusion_matrix(test_y, y5_pred)\n",
    "as5= accuracy_score(test_y, y5_pred)\n",
    "print()\n",
    "print(\"confusion matrix for k=5\")\n",
    "print(cm5)\n",
    "print(\"accuracy for k=5\",as5)\n",
    "print()\n",
    "maxaccu=max(as1,as3,as5)\n",
    "print(\"max accuracy\",maxaccu)\n",
    "print()\n",
    "if(maxaccu==as1):\n",
    "    print(\"K=1 has max accuracy\")\n",
    "elif(maxaccu==as3):\n",
    "    print(\"K=3 has max accuracy\")\n",
    "elif(maxaccu==as5):\n",
    "    print(\"K=5 has max accuracy\")\n",
    "    print()\n",
    "#question 2\n",
    "#min max normalization of traning data\n",
    "#normalising train data\n",
    "train_xx=train_x.copy()\n",
    "for col in train_x.columns:\n",
    "    newLowerBound=0\n",
    "    newUpperBound=1\n",
    "    mini = np.min(train_x[col])\n",
    "    maxi = np.max(train_x[col])\n",
    "    ranges = maxi - mini\n",
    "    newRange = newUpperBound - newLowerBound\n",
    "    old = train_x[col].values.tolist()\n",
    "    new = []\n",
    "    \n",
    "    for value in old:\n",
    "        y=((value - mini) / ranges) * newRange + newLowerBound\n",
    "        new.append(y)\n",
    "\n",
    "    train_x[col] = train_x[col].replace(old, new)\n",
    "\n",
    "#normalising test data\n",
    "\n",
    "for col in test_x.columns:\n",
    "    newLowerBound=0\n",
    "    newUpperBound=1\n",
    "    mini = np.min(train_xx[col])\n",
    "    maxi = np.max(train_xx[col])\n",
    "    ranges = maxi - mini\n",
    "    newRange = newUpperBound - newLowerBound\n",
    "    old=test_x[col].values.tolist()\n",
    "    new = []\n",
    "    \n",
    "    for value in old:\n",
    "        y=((value - mini) / ranges) * newRange + newLowerBound\n",
    "        new.append(y)\n",
    "\n",
    "    test_x[col] = test_x[col].replace(old, new)\n",
    "\n",
    "# saving the normalise data of train and test into csv file\n",
    "train_x.to_csv('SteelPlateFaults-train-Normalised.csv')\n",
    "test_x.to_csv('SteelPlateFaults-test-Normalised.csv')\n",
    "\n",
    "#part a and b of question 2\n",
    "print(\"question 2 part a and b\")\n",
    "#for K=1\n",
    "classifier1= KNeighborsClassifier(n_neighbors=1, metric='minkowski', p=2 )  \n",
    "classifier1.fit(train_x, train_y)\n",
    "\n",
    "#Predicting the test set result  \n",
    "y1_pred= classifier1.predict(test_x)  \n",
    "cm1= confusion_matrix(test_y, y1_pred)\n",
    "as1= accuracy_score(test_y, y1_pred)\n",
    "print(\"confusion matrix for k=1\")\n",
    "print(cm1)\n",
    "print(\"accuracy for k=1\",as1)\n",
    "\n",
    "#for K=3\n",
    "classifier3= KNeighborsClassifier(n_neighbors=3, metric='minkowski', p=2 )  \n",
    "classifier3.fit(train_x, train_y)\n",
    "\n",
    "#Predicting the test set result  \n",
    "y3_pred= classifier3.predict(test_x)  \n",
    "cm3= confusion_matrix(test_y, y3_pred)\n",
    "as3= accuracy_score(test_y, y3_pred)\n",
    "print()\n",
    "print(\"confusion matrix for k=3\")\n",
    "print(cm3)\n",
    "print(\"accuracy for k=3\",as3)\n",
    "\n",
    "#for K=5\n",
    "classifier5= KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2 ) \n",
    "classifier5.fit(train_x, train_y)\n",
    "\n",
    "#Predicting the test set result  \n",
    "y5_pred= classifier5.predict(test_x)  \n",
    "cm5= confusion_matrix(test_y, y5_pred)\n",
    "as5= accuracy_score(test_y, y5_pred)\n",
    "print()\n",
    "print(\"confusion matrix for k=5\")\n",
    "print(cm5)\n",
    "print(\"accuracy for k=5\",as5)\n",
    "print()\n",
    "maxaccu=max(as1,as3,as5)\n",
    "print(\"max accuracy\",maxaccu)\n",
    "print()\n",
    "if(maxaccu==as1):\n",
    "    print(\"K=1 has max accuracy\")\n",
    "elif(maxaccu==as3):\n",
    "    print(\"K=3 has max accuracy\")\n",
    "elif(maxaccu==as5):\n",
    "    print(\"K=5 has max accuracy\")\n",
    "#question 3\n",
    "print(\"question 3\")\n",
    "print()\n",
    "# Building a Bayes Classifier\n",
    "train = train.drop(['TypeOfSteel_A300', 'TypeOfSteel_A400', 'Y_Minimum', 'X_Minimum'], axis=1)\n",
    "test= test.drop(['TypeOfSteel_A300', 'TypeOfSteel_A400', 'Y_Minimum', 'X_Minimum'], axis=1)\n",
    "# splitting training dataset into its attributes and labels\n",
    "x_train = train.iloc[:, :-1].values\n",
    "y_train = train.iloc[:, train.shape[1] - 1].values\n",
    "# splitting testing dataset into its attributes and labels\n",
    "x_test = test.iloc[:, :-1].values\n",
    "y_test = test.iloc[:, test.shape[1] - 1].values\n",
    "\n",
    "\n",
    "# sample mean and covariance for class 0\n",
    "train00=pd.DataFrame(train0, columns=column)\n",
    "train00 = train00.drop(['TypeOfSteel_A300', 'TypeOfSteel_A400', 'Y_Minimum', 'X_Minimum'], axis=1)\n",
    "x_train0 = train00.iloc[:, :-1].values\n",
    "y_train0 = train00.iloc[:, train00.shape[1] - 1].values\n",
    "mean0 = np.mean(x_train0, axis=0)\n",
    "cov0 = np.cov(x_train0.T)\n",
    "column_num = [x for x in range(1, 24)]\n",
    "matrix0 = pd.DataFrame(x_train0, columns=column_num)\n",
    "covari0 = pd.DataFrame(matrix0.cov().T.round(decimals=3))\n",
    "covari0.to_csv('covariance_0.csv')\n",
    "print(\"Mean of class 0:\\n\",[round(x, 3) for x in mean0])\n",
    "# sample mean and covariance for class 1\n",
    "train11=pd.DataFrame(train1, columns=column)\n",
    "train11= train11.drop(['TypeOfSteel_A300', 'TypeOfSteel_A400', 'Y_Minimum', 'X_Minimum'], axis=1)\n",
    "x_train1 = train11.iloc[:, :-1].values\n",
    "y_train1 = train11.iloc[:, train11.shape[1] - 1].values\n",
    "mean1 = np.mean(x_train1, axis=0)\n",
    "cov1 = np.cov(x_train1.T)\n",
    "column_num = [x for x in range(1, 24)]\n",
    "matrix1 = pd.DataFrame(x_train1, columns=column_num)\n",
    "covari1 = pd.DataFrame(matrix1.cov().T.round(decimals=3))\n",
    "covari1.to_csv('covariance_1.csv')\n",
    "print()\n",
    "\n",
    "print(\"Mean of class 1:\\n\",[round(x, 3) for x in mean1])\n",
    "# calculating prior probability for each class\n",
    "prior0 = len(y_train0) / len(y_train)\n",
    "prior1 = len(y_train1) / len(y_train)\n",
    "\n",
    "#likelihood function\n",
    "def likelihood(x, mean, cov):\n",
    "    expo = -0.5 * np.dot(np.dot((x - mean).T, np.linalg.inv(cov)), (x - mean))\n",
    "    return (np.exp(expo)) / ((2 * np.pi) ** 11.5 * (np.linalg.det(cov)) ** 0.5)\n",
    "\n",
    "# calculate the likelihood and predicting class \n",
    "yy_pred = []\n",
    "for x in x_test:\n",
    "    likeh0 = likelihood(x, mean0, cov0) * prior0\n",
    "    likeh1 = likelihood(x, mean1, cov1) * prior1\n",
    "    if likeh0 > likeh1:\n",
    "        yy_pred.append(0)\n",
    "\n",
    "    else:\n",
    "        yy_pred.append(1)\n",
    "\n",
    "print(\"The confusion matrix for Bayes model\")\n",
    "print(confusion_matrix(y_test, yy_pred))\n",
    "print(\"The accuracy for Bayes model\")\n",
    "print(accuracy_score(y_test, yy_pred))\n",
    "#question 4\n",
    "print(\"question 4\")\n",
    "# Tabulating the best results of all three classifiers\n",
    "compare = {\"classifier\": [\"KNN\", \"KNN on normalised data\", \"Baye method\"],\n",
    "              \"accuracy (in decimal)\": [0.8961, 0.9556,0.9436]}\n",
    "tt=pd.DataFrame(compare)\n",
    "print(\"comparison b/w classifiers based upon classification accuracy\")\n",
    "print(tt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
